{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook/script directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Define the project root path\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))  \n",
    "\n",
    "# Add the scripts folder to the Python path\n",
    "src_path = os.path.join(project_root, 'scripts')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "from data_loading import load_csv,load_yfinance_data  \n",
    "from descriptive_statistic import dataset_summary,compute_basic_stats, count_unique_symbols\n",
    "#from publisher_analysis import publisher_sentiment_analysis\n",
    "from text_analysis import (\n",
    "    sentiment_analysis_vader, sentiment_analysis_textblob, combined_sentiment,\n",
    "    sentiment_by_stock, generate_wordcloud, analyze_ngrams,\n",
    "    extract_topics_from_headlines, perform_ner, plot_sentiment_distribution\n",
    ")\n",
    "from time_series_analysis import (\n",
    "    publication_frequency_analysis, stl_decomposition, \n",
    "    time_of_day_analysis, moving_average_analysis, weekday_analysis\n",
    ")\n",
    "from publisher_analysis import (\n",
    "    top_publishers, email_domain_analysis, news_type_analysis,\n",
    "    unique_publishers_over_time, publisher_domain_analysis\n",
    ")\n",
    "from technical_analysis import add_technical_indicators\n",
    "#from financial_metrics import calculate_financial_metrics \n",
    "from data_visualization import (\n",
    "    plot_macd,plot_rsi,plot_stock_data_with_indicators,\n",
    "    plot_boxplot, plot_volume_trends, plot_stock_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from C:\\Users\\HP\\Desktop\\week - 1\\Data\\raw_analyst_ratings\\raw_analyst_ratings.csv. Shape: (1407328, 6)\n",
      "\n",
      "Raw Analyst Ratings Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1407328 entries, 0 to 1407327\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Unnamed: 0  1407328 non-null  int64 \n",
      " 1   headline    1407328 non-null  object\n",
      " 2   url         1407328 non-null  object\n",
      " 3   publisher   1407328 non-null  object\n",
      " 4   date        1407328 non-null  object\n",
      " 5   stock       1407328 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 64.4+ MB\n",
      "None\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file paths\n",
    "analyst_ratings_path = r\"C:\\Users\\HP\\Desktop\\week - 1\\Data\\raw_analyst_ratings\\raw_analyst_ratings.csv\"\n",
    "yfinance_folder_path = r\"C:\\Users\\HP\\Desktop\\week - 1\\Data\\yfinance_data\\yfinance_data\"\n",
    "\n",
    "# Load data\n",
    "raw_analyst_ratings = load_csv(analyst_ratings_path)\n",
    "#yfinance_data = load_yfinance_data(yfinance_folder_path)\n",
    "\n",
    "# Inspect Raw Analyst Ratings\n",
    "print(\"\\nRaw Analyst Ratings Info:\")\n",
    "print(raw_analyst_ratings.info())\n",
    "print(raw_analyst_ratings.head())\n",
    "\n",
    "# # Inspect YFinance Data\n",
    "# print(\"\\nYFinance Data Keys (Stocks):\", list(yfinance_data.keys()))\n",
    "# if 'AAPL_historical_data' in yfinance_data:\n",
    "#     print(\"\\nSample AAPL Data:\")\n",
    "#     print(yfinance_data['AAPL_historical_data'].head())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Dataset Summary ===\")\n",
    "print(dataset_summary(raw_analyst_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headline Statistics\n",
    "print(\"\\n=== Headline Statistics ===\")\n",
    "print(compute_basic_stats(raw_analyst_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Stock Symbols\n",
    "print(\"\\n=== Stock Symbol Analysis ===\")\n",
    "print(count_unique_symbols(raw_analyst_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop Unnamed: 0 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " raw_analyst_ratings = raw_analyst_ratings.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DataFrame Info:\")\n",
    "raw_analyst_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate basic statistics for headline length\n",
    "raw_analyst_ratings['headline_length'] = raw_analyst_ratings['headline'].apply(len)\n",
    "print(\"\\nHeadline Length Statistics:\")\n",
    "print(raw_analyst_ratings['headline_length'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings = sentiment_analysis_vader(raw_analyst_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis using text blob\n",
    "raw_analyst_ratings = sentiment_analysis_textblob(raw_analyst_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis using both vader and textblob\n",
    "raw_analyst_ratings = combined_sentiment(raw_analyst_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_analyst_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Word Cloud\n",
    "generate_wordcloud(raw_analyst_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Significant Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Significant Topics\n",
    "print(\"\\n=== Extracting Significant Topics ===\")\n",
    "extract_topics_from_headlines(raw_analyst_ratings, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze Bi-grams\n",
    "analyze_ngrams(raw_analyst_ratings, n=2, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform NER\n",
    "# print(\"\\n=== Named Entity Recognition ===\")\n",
    "# perform_ner(raw_analyst_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify unique publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_publishers = raw_analyst_ratings['publisher'].nunique()\n",
    "print(f\"\\nNumber of Unique Publishers: {unique_publishers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze top publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Top Publishers ===\")\n",
    "print(top_publishers(raw_analyst_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze email domains in publisher names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Email Domain Analysis ===\")\n",
    "print(email_domain_analysis(raw_analyst_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze news types reported by publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== News Type Analysis ===\")\n",
    "keyword_list = ['FDA', 'approval', 'price target', 'earnings']\n",
    "news_type_df = news_type_analysis(raw_analyst_ratings, keyword_list=keyword_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze unique publishers over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Unique Publishers Over Time ===\")\n",
    "print(unique_publishers_over_time(raw_analyst_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analyze publisher domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Publisher Domain Analysis ===\")\n",
    "print(publisher_domain_analysis(raw_analyst_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis (Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we perform `sentiment analysis` on financial news headlines using **VADER (Valance Aware Dictionary anssEntiment Reasoner)** sentiment analysis tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_analyst_ratings['date'].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "raw_analyst_ratings['date'] = pd.to_datetime(\n",
    "    raw_analyst_ratings['date'], \n",
    "    format=\"%Y-%m-%d %H:%M:%S\", \n",
    "    errors=\"coerce\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dates = raw_analyst_ratings[raw_analyst_ratings['date'].isna()]\n",
    "print(f\"Number of invalid dates: {len(invalid_dates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the rows with invalid dates\n",
    "print(\"Sample of invalid dates:\")\n",
    "print(invalid_dates[['date']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = raw_analyst_ratings.shape[0]\n",
    "invalid_dates_count = raw_analyst_ratings['date'].isna().sum()\n",
    "invalid_date_percentage = (invalid_dates_count / total_rows) * 100\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Invalid dates: {invalid_dates_count} ({invalid_date_percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaT values in the 'date' column\n",
    "raw_analyst_ratings = raw_analyst_ratings.dropna(subset=['date'])\n",
    "\n",
    "# Verify the new shape of the dataset\n",
    "print(f\"Dataset after dropping invalid dates: {raw_analyst_ratings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_dates = raw_analyst_ratings[raw_analyst_ratings['date'].isna()]\n",
    "print(f\"Number of invalid dates: {len(invalid_dates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the earliest and latest publication dates\n",
    "print(\"\\nPublication Date Range:\")\n",
    "print(raw_analyst_ratings['date'].min(), \"to\", raw_analyst_ratings['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of articles published per day\n",
    "articles_per_day = raw_analyst_ratings.groupby(raw_analyst_ratings['date'].dt.date).size()\n",
    "print(\"\\nArticles Per Day:\")\n",
    "print(articles_per_day.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the days with the highest number of publications\n",
    "print(\"\\nTop 5 Dates with the Most Articles:\")\n",
    "print(articles_per_day.nlargest(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on Stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the combined DataFrame:\n",
      "         Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
      "0  1980-12-12  0.128348  0.128906  0.128348  0.128348   0.098943  469033600   \n",
      "1  1980-12-15  0.122210  0.122210  0.121652  0.121652   0.093781  175884800   \n",
      "2  1980-12-16  0.113281  0.113281  0.112723  0.112723   0.086898  105728000   \n",
      "3  1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089049   86441600   \n",
      "4  1980-12-18  0.118862  0.119420  0.118862  0.118862   0.091630   73449600   \n",
      "\n",
      "   Dividends  Stock Splits Stock  \n",
      "0        0.0           0.0  AAPL  \n",
      "1        0.0           0.0  AAPL  \n",
      "2        0.0           0.0  AAPL  \n",
      "3        0.0           0.0  AAPL  \n",
      "4        0.0           0.0  AAPL  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df_stocks = load_yfinance_data(yfinance_folder_path)\n",
    "\n",
    "# Preview the data\n",
    "print(\"First 5 rows of the combined DataFrame:\")\n",
    "print(df_stocks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total Rows': 45428,\n",
       " 'Total Columns': 10,\n",
       " 'Missing Values': {'Date': 0,\n",
       "  'Open': 0,\n",
       "  'High': 0,\n",
       "  'Low': 0,\n",
       "  'Close': 0,\n",
       "  'Adj Close': 0,\n",
       "  'Volume': 0,\n",
       "  'Dividends': 0,\n",
       "  'Stock Splits': 0,\n",
       "  'Stock': 0},\n",
       " 'Data Types': {'Date': dtype('O'),\n",
       "  'Open': dtype('float64'),\n",
       "  'High': dtype('float64'),\n",
       "  'Low': dtype('float64'),\n",
       "  'Close': dtype('float64'),\n",
       "  'Adj Close': dtype('float64'),\n",
       "  'Volume': dtype('int64'),\n",
       "  'Dividends': dtype('float64'),\n",
       "  'Stock Splits': dtype('float64'),\n",
       "  'Stock': dtype('O')}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_summary(df_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(df_stocks['Stock'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL' 'AMZN' 'GOOG' 'META' 'MSFT' 'NVDA' 'TSLA']\n"
     ]
    }
   ],
   "source": [
    "print(df_stocks['Stock'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
