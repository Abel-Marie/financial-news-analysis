{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for data manipulation\n",
    "# import pandas as pd\n",
    "\n",
    "# # For visualization\n",
    "# import matplotlib.pyplot as pyplot\n",
    "# import seaborn as sns\n",
    "\n",
    "# # for date/time manipulationimport datetime\n",
    "\n",
    "# #fot nlp\n",
    "# import nltk\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "\n",
    "# # for numerical analysis\n",
    "# import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.data_loading'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary modules\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_stock_data\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_data_structure\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtechnical_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_technical_indicators\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scripts.data_loading'"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "from scripts.data_loading import load_stock_data\n",
    "from scripts.data_validation import validate_data_structure\n",
    "from scripts.technical_analysis import calculate_technical_indicators\n",
    "from scripts.financial_metrics import fetch_financial_metrics\n",
    "from scripts.data_visualization import plot_stock_data, plot_rsi, plot_macd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "#import os\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary modules\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_csv, load_yfinance_data\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Define file paths\u001b[39;00m\n\u001b[0;32m      6\u001b[0m analyst_ratings_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mweek - 1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraw_analyst_ratings\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraw_analyst_ratings.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scripts.dataloader'"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scripts.dataloader import load_csv, load_yfinance_data\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "analyst_ratings_path = r\"C:\\Users\\HP\\Desktop\\week - 1\\Data\\raw_analyst_ratings\\raw_analyst_ratings.csv\"\n",
    "yfinance_folder_path = r\"C:\\Users\\HP\\Desktop\\week - 1\\Data\\yfinance_data\"\n",
    "\n",
    "# Load data\n",
    "raw_analyst_ratings = load_csv(analyst_ratings_path)\n",
    "yfinance_data = load_yfinance_data(yfinance_folder_path)\n",
    "\n",
    "# Inspect Raw Analyst Ratings\n",
    "print(\"\\nRaw Analyst Ratings Info:\")\n",
    "print(raw_analyst_ratings.info())\n",
    "print(raw_analyst_ratings.head())\n",
    "\n",
    "# Inspect YFinance Data\n",
    "print(\"\\nYFinance Data Keys (Stocks):\", list(yfinance_data.keys()))\n",
    "if 'AAPL_historical_data' in yfinance_data:\n",
    "    print(\"\\nSample AAPL Data:\")\n",
    "    print(yfinance_data['AAPL_historical_data'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# def load_data():\n",
    "#     \"\"\"\n",
    "#     Load all data files from the 'yfinance_data' and 'raw_analyst_ratings' folders.\n",
    "    \n",
    "#     Returns:\n",
    "#         stock_data (dict): A dictionary containing stock data DataFrames.\n",
    "#         raw_analyst_ratings (pd.DataFrame): DataFrame containing raw analyst ratings.\n",
    "#     \"\"\"\n",
    "#     # Define the paths\n",
    "#     yfinance_folder = r'C:\\Users\\HP\\Desktop\\week - 1\\Data\\yfinance_data'\n",
    "#     analyst_ratings_file = r'C:\\Users\\HP\\Desktop\\week - 1\\Data\\raw_analyst_ratings\\raw_analyst_ratings.csv'\n",
    "    \n",
    "#     # Initialize a dictionary to store stock DataFrames\n",
    "#     stock_data = {}\n",
    "#     raw_analyst_ratings = None\n",
    "    \n",
    "#     # Load yfinance data files\n",
    "#     if os.path.exists(yfinance_folder):\n",
    "#         yfinance_files = [f for f in os.listdir(yfinance_folder) if f.endswith('.csv')]\n",
    "#         for file in yfinance_files:\n",
    "#             file_path = os.path.join(yfinance_folder, file)\n",
    "#             stock_name = os.path.splitext(file)[0]  # Extract stock name without extension\n",
    "#             print(f\"Loading file: {file} as stock: {stock_name}\")\n",
    "#             stock_data[stock_name] = pd.read_csv(file_path)\n",
    "    \n",
    "#     # Load raw analyst ratings file\n",
    "#     if os.path.exists(analyst_ratings_file):\n",
    "#         print(f\"Loading raw analyst ratings from: {analyst_ratings_file}\")\n",
    "#         raw_analyst_ratings = pd.read_csv(analyst_ratings_file)\n",
    "    \n",
    "#     return stock_data, raw_analyst_ratings\n",
    "\n",
    "# # Call the function to load the data\n",
    "# stock_data, raw_analyst_ratings = load_data()\n",
    "\n",
    "# # Debug: Print available stock data keys\n",
    "# print(\"Loaded stock data keys:\", stock_data.keys())\n",
    "\n",
    "# # Access and check raw analyst ratings\n",
    "# if raw_analyst_ratings is not None:\n",
    "#     print(\"\\nRaw Analyst Ratings DataFrame Info:\")\n",
    "#     print(raw_analyst_ratings.info())\n",
    "\n",
    "#     print(\"\\nRaw Analyst Ratings Shape:\")\n",
    "#     print(raw_analyst_ratings.shape)\n",
    "\n",
    "#     print(\"\\nFirst few rows of Raw Analyst Ratings:\")\n",
    "#     print(raw_analyst_ratings.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1407328 entries, 0 to 1407327\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Unnamed: 0  1407328 non-null  int64 \n",
      " 1   headline    1407328 non-null  object\n",
      " 2   url         1407328 non-null  object\n",
      " 3   publisher   1407328 non-null  object\n",
      " 4   date        1407328 non-null  object\n",
      " 5   stock       1407328 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 64.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check basic information about the DataFrame\n",
    "print(\"DataFrame Info:\")\n",
    "raw_analyst_ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for null values\n",
    "# print(\"\\nNull Values per Column:\")\n",
    "# print(raw_analyst_ratings.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop Unnamed: 0 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_analyst_ratings = raw_analyst_ratings.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"DataFrame Info:\")\n",
    "# raw_analyst_ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Length Analysi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate basic statistics for headline length\n",
    "# raw_analyst_ratings['headline_length'] = raw_analyst_ratings['headline'].apply(len)\n",
    "# print(\"\\nHeadline Length Statistics:\")\n",
    "# print(raw_analyst_ratings['headline_length'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the number of articles per publisher\n",
    "# publisher_counts = raw_analyst_ratings['publisher'].value_counts()\n",
    "# print(\"\\nTop Publishers by Article Count:\")\n",
    "# print(publisher_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publication Date Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis (Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we perform `sentiment analysis` on financial news headlines using **VADER (Valance Aware Dictionary anssEntiment Reasoner)** sentiment analysis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Category Counts:\n",
      "sentiment_category\n",
      "Neutral     739338\n",
      "Positive    442930\n",
      "Negative    225060\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply sentiment analysis to the headlines\n",
    "raw_analyst_ratings['sentiment_score'] = raw_analyst_ratings['headline'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Categorize sentiment as Positive, Negative, or Neutral\n",
    "raw_analyst_ratings['sentiment_category'] = raw_analyst_ratings['sentiment_score'].apply(\n",
    "    lambda score: 'Positive' if score > 0.05 else ('Negative' if score < -0.05 else 'Neutral')\n",
    ")\n",
    "\n",
    "# Display sentiment statistics\n",
    "print(\"\\nSentiment Category Counts:\")\n",
    "print(raw_analyst_ratings['sentiment_category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2020-06-05 10:30:54-04:00\n",
      "1     2020-06-03 10:45:20-04:00\n",
      "2     2020-05-26 04:30:07-04:00\n",
      "3     2020-05-22 12:45:06-04:00\n",
      "4     2020-05-22 11:38:59-04:00\n",
      "5     2020-05-22 11:23:25-04:00\n",
      "6     2020-05-22 09:36:20-04:00\n",
      "7     2020-05-22 09:07:04-04:00\n",
      "8     2020-05-22 08:37:59-04:00\n",
      "9     2020-05-22 08:06:17-04:00\n",
      "10          2020-05-22 00:00:00\n",
      "11          2020-05-22 00:00:00\n",
      "12          2020-05-21 00:00:00\n",
      "13          2020-05-21 00:00:00\n",
      "14          2020-05-21 00:00:00\n",
      "15          2020-05-21 00:00:00\n",
      "16          2020-05-18 00:00:00\n",
      "17          2020-05-16 00:00:00\n",
      "18          2020-05-15 00:00:00\n",
      "19          2020-05-08 00:00:00\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(raw_analyst_ratings['date'].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime format\n",
    "raw_analyst_ratings['date'] = pd.to_datetime(\n",
    "    raw_analyst_ratings['date'], \n",
    "    format=\"%Y-%m-%d %H:%M:%S\", \n",
    "    errors=\"coerce\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid dates: 55987\n"
     ]
    }
   ],
   "source": [
    "invalid_dates = raw_analyst_ratings[raw_analyst_ratings['date'].isna()]\n",
    "print(f\"Number of invalid dates: {len(invalid_dates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of invalid dates:\n",
      "     date\n",
      "0     NaT\n",
      "1     NaT\n",
      "2     NaT\n",
      "3     NaT\n",
      "4     NaT\n",
      "5     NaT\n",
      "6     NaT\n",
      "7     NaT\n",
      "8     NaT\n",
      "9     NaT\n",
      "1433  NaT\n",
      "1434  NaT\n",
      "1435  NaT\n",
      "1436  NaT\n",
      "1437  NaT\n",
      "1438  NaT\n",
      "1439  NaT\n",
      "1440  NaT\n",
      "1441  NaT\n",
      "1442  NaT\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the rows with invalid dates\n",
    "print(\"Sample of invalid dates:\")\n",
    "print(invalid_dates[['date']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 1407328\n",
      "Invalid dates: 55987 (3.98%)\n"
     ]
    }
   ],
   "source": [
    "total_rows = raw_analyst_ratings.shape[0]\n",
    "invalid_dates_count = raw_analyst_ratings['date'].isna().sum()\n",
    "invalid_date_percentage = (invalid_dates_count / total_rows) * 100\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Invalid dates: {invalid_dates_count} ({invalid_date_percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after dropping invalid dates: (1351341, 8)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaT values in the 'date' column\n",
    "raw_analyst_ratings = raw_analyst_ratings.dropna(subset=['date'])\n",
    "\n",
    "# Verify the new shape of the dataset\n",
    "print(f\"Dataset after dropping invalid dates: {raw_analyst_ratings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid dates: 0\n"
     ]
    }
   ],
   "source": [
    "invalid_dates = raw_analyst_ratings[raw_analyst_ratings['date'].isna()]\n",
    "print(f\"Number of invalid dates: {len(invalid_dates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Publication Date Range:\n",
      "2009-02-14 00:00:00 to 2020-06-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Check for the earliest and latest publication dates\n",
    "print(\"\\nPublication Date Range:\")\n",
    "print(raw_analyst_ratings['date'].min(), \"to\", raw_analyst_ratings['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Articles Per Day:\n",
      "date\n",
      "2009-02-14    1\n",
      "2009-04-27    2\n",
      "2009-04-29    1\n",
      "2009-05-22    1\n",
      "2009-05-27    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of articles published per day\n",
    "articles_per_day = raw_analyst_ratings.groupby(raw_analyst_ratings['date'].dt.date).size()\n",
    "print(\"\\nArticles Per Day:\")\n",
    "print(articles_per_day.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Dates with the Most Articles:\n",
      "date\n",
      "2020-03-12    1766\n",
      "2020-02-27    1292\n",
      "2020-02-28    1239\n",
      "2019-08-01    1228\n",
      "2020-03-06    1147\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify the days with the highest number of publications\n",
    "print(\"\\nTop 5 Dates with the Most Articles:\")\n",
    "print(articles_per_day.nlargest(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Unique Publishers: 1029\n"
     ]
    }
   ],
   "source": [
    "# Identify unique publishers\n",
    "unique_publishers = raw_analyst_ratings['publisher'].nunique()\n",
    "print(f\"\\nNumber of Unique Publishers: {unique_publishers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the most frequent domains (if publishers use email-style names)\n",
    "if '@' in str(raw_analyst_ratings['publisher'].iloc[0]):  # Check for email-like names\n",
    "    raw_analyst_ratings['publisher_domain'] = raw_analyst_ratings['publisher'].str.split('@').str[-1]\n",
    "    domain_counts = raw_analyst_ratings['publisher_domain'].value_counts()\n",
    "    print(\"\\nTop 5 Publisher Domains:\")\n",
    "    print(domain_counts.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Publisher Analysi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Sentiment with Stock Prrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
